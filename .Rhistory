library(leaflet)
library(rgdal)
library(htmltools)
library(readr)
library(readxl)
library(chorddiag)   # d3 chord plot
library(maptools)    # SpatialPolygons2PolySet
library(PBSmapping)  # calcCentroid
library(geosphere)   # desire lines
# Chunk 3: custom functions
# function to compute row / column sums
add_marginals <- function(df) {
df2 <- as.data.frame(df)
cnames <- c(colnames(df), "total")
rnames <- c(row.names(df),"total")
df2 <- rbind(df2, colSums(df2))
df2 <- cbind(df2, rowSums(df2))
row.names(df2) <- rnames
colnames(df2) <- cnames
return(df2)
}
# function to remove "total" from the matrix
remove_marginals <- function(df){
df2 <- df %>% select(-total) %>% filter(names(df) != "total")
return(df2)
}
csvFiles <- dir(paste(projDir,"/airsage",sep=""), pattern = ".csv")
for (c in 1:length(csvFiles)){
data <- read.csv(paste0("airsage/",csvFiles[c]))
nrows <- nrow(data)
ntrips <- sum(data$Count)
samples <- cbind(csvFiles[c], nrows, ntrips)
ifelse (c ==1 , all_samples <- samples, all_samples <- rbind(all_samples, samples))
ifelse (c ==1 , count <- nrows, count <- count + nrows)
ifelse (c ==1 , trips <- ntrips, trips <- trips + ntrips)
}
all <- data.frame(all_samples, stringsAsFactors = FALSE)
all <- rbind(all, c("Total",count, trips))
all <- all %>% mutate(trip_per_sample = 100 * as.numeric(ntrips) / as.numeric(nrows))
all <- all %>% mutate(pct_samples = 100 * as.numeric(nrows) / count)
all <- all %>% mutate(pct_trips = 100 * as.numeric(ntrips) / trips)
names(all) <- c("File", "Samples", "Trips","Trips/Samples" ,"% Sample", "% Trips")
print(kable(all,format.args = list(big.mark = ","), digits = 0))
# Chunk 1: user settings
knitr::opts_chunk$set(echo = TRUE, fig.width = 9.5)
# User inputs:
projDir         <- "/Users/amarsarvepalli/Desktop/github/Flagler"
# Airsage data files
airsage_data    <- c("airsage/trip_leg_matrix_cusWDH.csv",
"airsage/trip_leg_matrix_cusWDDP.csv",
"airsage/trip_leg_submatrix_cusWDDP.csv",
"airsage/trip_leg_submatrix_cusWDH.csv")
airsage_shapeFile <- "airsage/airsarge_districts/TAZs.shp"
airsage_Districts <- "airsage/airsarge_districts/district_equivalency.csv"
# Define corridor districts
Study_districts <- c(20:40)
# Gtfs network
gtfsShapesFile <- "GTFS/miami-dade-transit_20150626_0146/shapes.txt"
gtfsTripsFile <- "GTFS/miami-dade-transit_20150626_0146/trips.txt"
gtfsRoutesFile <- "GTFS/miami-dade-transit_20150626_0146/routes.txt"
routeName <- "flagler"
# Census ACS and CTPP data files
# ctpp_flowFile <- "acs_data/MiamiDade_CTPP_A302103.csv"
ctpp_zipFile <- "acs_data/MiamiDade_CTPP_A302103.zip"
acs_shapeFile     <- "acs_data/Miami_Dade_Census_Tracts.shp"
acs_airsage_dist <- "acs_data/tract_district_eqiv.csv"
acs_demoFile <- "acs_data/selected_acs_data.csv"
# APC data
apc_dir <- "bus_apc_data/Flagler St BRTStudy APC Data Oct 2015_Xlsx"
apc_tag_districts <- "bus_apc_data/Flagler St BRTStudy APC Data Oct 2015_Xlsx/apc_data_gecoded_districts.csv"
# Output files
daily_od_matrix <- "daily_od_trips_by_airsage_districts.csv"
peak_od_matrix <- "peak_od_trips_by_airsage_districts.csv"
daily_od_submatrix <- "daily_od_sub_trips_by_airsage_districts.csv"
peak_od_submatrix <- "peak_od_sub_trips_by_airsage_districts.csv"
jtw_trn_matrix <- "JTW_trn_trips_by_airsage_districts.csv"
apc_trn_boardings <- "apc_trn_boardings.csv"
# Chunk 2: setup
# load libraries
library(tidyr)
library(dplyr)
library(knitr)
library(leaflet)
library(rgdal)
library(htmltools)
library(readr)
library(readxl)
library(chorddiag)   # d3 chord plot
library(maptools)    # SpatialPolygons2PolySet
library(PBSmapping)  # calcCentroid
library(geosphere)   # desire lines
# Chunk 3: custom functions
# function to compute row / column sums
add_marginals <- function(df) {
df2 <- as.data.frame(df)
cnames <- c(colnames(df), "total")
rnames <- c(row.names(df),"total")
df2 <- rbind(df2, colSums(df2))
df2 <- cbind(df2, rowSums(df2))
row.names(df2) <- rnames
colnames(df2) <- cnames
return(df2)
}
# function to remove "total" from the matrix
remove_marginals <- function(df){
df2 <- df %>% select(-total) %>% filter(names(df) != "total")
return(df2)
}
# Chunk 4: read data
csvFiles <- dir(paste(projDir,"/airsage",sep=""), pattern = ".csv")
for (c in 1:length(csvFiles)){
data <- read.csv(paste0("airsage/",csvFiles[c]))
nrows <- nrow(data)
ntrips <- sum(data$Count)
samples <- cbind(csvFiles[c], nrows, ntrips)
ifelse (c ==1 , all_samples <- samples, all_samples <- rbind(all_samples, samples))
ifelse (c ==1 , count <- nrows, count <- count + nrows)
ifelse (c ==1 , trips <- ntrips, trips <- trips + ntrips)
}
all <- data.frame(all_samples, stringsAsFactors = FALSE)
all <- rbind(all, c("Total",count, trips))
all <- all %>% mutate(trip_per_sample = 100 * as.numeric(ntrips) / as.numeric(nrows))
all <- all %>% mutate(pct_samples = 100 * as.numeric(nrows) / count)
all <- all %>% mutate(pct_trips = 100 * as.numeric(ntrips) / trips)
names(all) <- c("File", "Samples", "Trips","Trips/Samples" ,"% Sample", "% Trips")
print(kable(all,format.args = list(big.mark = ","), digits = 0))
data_wddp <- read.csv("airsage/trip_leg_matrix_cusWDDP.csv")
data_wdh <- read.csv("airsage/trip_leg_matrix_cusWDH.csv")
data_wddp$tod <- "peak"
data_wdh$tod <- "24H"
data <- rbind(data_wddp, data_wdh)
print(head(data))
# Chunk 1: user settings
knitr::opts_chunk$set(echo = TRUE, fig.width = 9.5)
# User inputs:
projDir         <- "/Users/amarsarvepalli/Desktop/github/Flagler"
# Airsage data files
airsage_data    <- c("airsage/trip_leg_matrix_cusWDH.csv",
"airsage/trip_leg_matrix_cusWDDP.csv",
"airsage/trip_leg_submatrix_cusWDDP.csv",
"airsage/trip_leg_submatrix_cusWDH.csv")
airsage_shapeFile <- "airsage/airsarge_districts/TAZs.shp"
airsage_Districts <- "airsage/airsarge_districts/district_equivalency.csv"
# Define corridor districts
Study_districts <- c(20:40)
# Gtfs network
gtfsShapesFile <- "GTFS/miami-dade-transit_20150626_0146/shapes.txt"
gtfsTripsFile <- "GTFS/miami-dade-transit_20150626_0146/trips.txt"
gtfsRoutesFile <- "GTFS/miami-dade-transit_20150626_0146/routes.txt"
routeName <- "flagler"
# Census ACS and CTPP data files
# ctpp_flowFile <- "acs_data/MiamiDade_CTPP_A302103.csv"
ctpp_zipFile <- "acs_data/MiamiDade_CTPP_A302103.zip"
acs_shapeFile     <- "acs_data/Miami_Dade_Census_Tracts.shp"
acs_airsage_dist <- "acs_data/tract_district_eqiv.csv"
acs_demoFile <- "acs_data/selected_acs_data.csv"
# APC data
apc_dir <- "bus_apc_data/Flagler St BRTStudy APC Data Oct 2015_Xlsx"
apc_tag_districts <- "bus_apc_data/Flagler St BRTStudy APC Data Oct 2015_Xlsx/apc_data_gecoded_districts.csv"
# Output files
daily_od_matrix <- "daily_od_trips_by_airsage_districts.csv"
peak_od_matrix <- "peak_od_trips_by_airsage_districts.csv"
daily_od_submatrix <- "daily_od_sub_trips_by_airsage_districts.csv"
peak_od_submatrix <- "peak_od_sub_trips_by_airsage_districts.csv"
jtw_trn_matrix <- "JTW_trn_trips_by_airsage_districts.csv"
apc_trn_boardings <- "apc_trn_boardings.csv"
# Chunk 2: setup
# load libraries
library(tidyr)
library(dplyr)
library(knitr)
library(leaflet)
library(rgdal)
library(htmltools)
library(readr)
library(readxl)
library(chorddiag)   # d3 chord plot
library(maptools)    # SpatialPolygons2PolySet
library(PBSmapping)  # calcCentroid
library(geosphere)   # desire lines
# Chunk 3: custom functions
# function to compute row / column sums
add_marginals <- function(df) {
df2 <- as.data.frame(df)
cnames <- c(colnames(df), "total")
rnames <- c(row.names(df),"total")
df2 <- rbind(df2, colSums(df2))
df2 <- cbind(df2, rowSums(df2))
row.names(df2) <- rnames
colnames(df2) <- cnames
return(df2)
}
# function to remove "total" from the matrix
remove_marginals <- function(df){
df2 <- df %>% select(-total) %>% filter(names(df) != "total")
return(df2)
}
# Chunk 4: read data
csvFiles <- dir(paste(projDir,"/airsage",sep=""), pattern = ".csv")
for (c in 1:length(csvFiles)){
data <- read.csv(paste0("airsage/",csvFiles[c]))
nrows <- nrow(data)
ntrips <- sum(data$Count)
samples <- cbind(csvFiles[c], nrows, ntrips)
ifelse (c ==1 , all_samples <- samples, all_samples <- rbind(all_samples, samples))
ifelse (c ==1 , count <- nrows, count <- count + nrows)
ifelse (c ==1 , trips <- ntrips, trips <- trips + ntrips)
}
all <- data.frame(all_samples, stringsAsFactors = FALSE)
all <- rbind(all, c("Total",count, trips))
all <- all %>% mutate(trip_per_sample = 100 * as.numeric(ntrips) / as.numeric(nrows))
all <- all %>% mutate(pct_samples = 100 * as.numeric(nrows) / count)
all <- all %>% mutate(pct_trips = 100 * as.numeric(ntrips) / trips)
names(all) <- c("File", "Samples", "Trips","Trips/Samples" ,"% Sample", "% Trips")
print(kable(all,format.args = list(big.mark = ","), digits = 0))
# Chunk 5: daily & peak trips
data_wddp <- read.csv("airsage/trip_leg_matrix_cusWDDP.csv")
data_wdh <- read.csv("airsage/trip_leg_matrix_cusWDH.csv")
data_wddp$tod <- "peak"
data_wdh$tod <- "24H"
data <- rbind(data_wddp, data_wdh)
print(head(data))
# Total trips
total_trips <- data %>% group_by(tod) %>% summarize(sum = sum(Count))
kable(total_trips,format.args = list(big.mark = ","), digits = 0)
# Chunk 1: user settings
knitr::opts_chunk$set(echo = TRUE, fig.width = 9.5)
# User inputs:
projDir         <- "/Users/amarsarvepalli/Desktop/github/Flagler"
# Airsage data files
airsage_data    <- c("airsage/trip_leg_matrix_cusWDH.csv",
"airsage/trip_leg_matrix_cusWDDP.csv",
"airsage/trip_leg_submatrix_cusWDDP.csv",
"airsage/trip_leg_submatrix_cusWDH.csv")
airsage_shapeFile <- "airsage/airsarge_districts/TAZs.shp"
airsage_Districts <- "airsage/airsarge_districts/district_equivalency.csv"
# Define corridor districts
Study_districts <- c(20:40)
# Gtfs network
gtfsShapesFile <- "GTFS/miami-dade-transit_20150626_0146/shapes.txt"
gtfsTripsFile <- "GTFS/miami-dade-transit_20150626_0146/trips.txt"
gtfsRoutesFile <- "GTFS/miami-dade-transit_20150626_0146/routes.txt"
routeName <- "flagler"
# Census ACS and CTPP data files
# ctpp_flowFile <- "acs_data/MiamiDade_CTPP_A302103.csv"
ctpp_zipFile <- "acs_data/MiamiDade_CTPP_A302103.zip"
acs_shapeFile     <- "acs_data/Miami_Dade_Census_Tracts.shp"
acs_airsage_dist <- "acs_data/tract_district_eqiv.csv"
acs_demoFile <- "acs_data/selected_acs_data.csv"
# APC data
apc_dir <- "bus_apc_data/Flagler St BRTStudy APC Data Oct 2015_Xlsx"
apc_tag_districts <- "bus_apc_data/Flagler St BRTStudy APC Data Oct 2015_Xlsx/apc_data_gecoded_districts.csv"
# Output files
daily_od_matrix <- "daily_od_trips_by_airsage_districts.csv"
peak_od_matrix <- "peak_od_trips_by_airsage_districts.csv"
daily_od_submatrix <- "daily_od_sub_trips_by_airsage_districts.csv"
peak_od_submatrix <- "peak_od_sub_trips_by_airsage_districts.csv"
jtw_trn_matrix <- "JTW_trn_trips_by_airsage_districts.csv"
apc_trn_boardings <- "apc_trn_boardings.csv"
# Chunk 2: setup
# load libraries
library(tidyr)
library(dplyr)
library(knitr)
library(leaflet)
library(rgdal)
library(htmltools)
library(readr)
library(readxl)
library(chorddiag)   # d3 chord plot
library(maptools)    # SpatialPolygons2PolySet
library(PBSmapping)  # calcCentroid
library(geosphere)   # desire lines
# Chunk 3: custom functions
# function to compute row / column sums
add_marginals <- function(df) {
df2 <- as.data.frame(df)
cnames <- c(colnames(df), "total")
rnames <- c(row.names(df),"total")
df2 <- rbind(df2, colSums(df2))
df2 <- cbind(df2, rowSums(df2))
row.names(df2) <- rnames
colnames(df2) <- cnames
return(df2)
}
# function to remove "total" from the matrix
remove_marginals <- function(df){
df2 <- df %>% select(-total) %>% filter(names(df) != "total")
return(df2)
}
# Chunk 4: read data
csvFiles <- dir(paste(projDir,"/airsage",sep=""), pattern = ".csv")
for (c in 1:length(csvFiles)){
data <- read.csv(paste0("airsage/",csvFiles[c]))
nrows <- nrow(data)
ntrips <- sum(data$Count)
samples <- cbind(csvFiles[c], nrows, ntrips)
ifelse (c ==1 , all_samples <- samples, all_samples <- rbind(all_samples, samples))
ifelse (c ==1 , count <- nrows, count <- count + nrows)
ifelse (c ==1 , trips <- ntrips, trips <- trips + ntrips)
}
all <- data.frame(all_samples, stringsAsFactors = FALSE)
all <- rbind(all, c("Total",count, trips))
all <- all %>% mutate(trip_per_sample = 100 * as.numeric(ntrips) / as.numeric(nrows))
all <- all %>% mutate(pct_samples = 100 * as.numeric(nrows) / count)
all <- all %>% mutate(pct_trips = 100 * as.numeric(ntrips) / trips)
names(all) <- c("File", "Samples", "Trips","Trips/Samples" ,"% Sample", "% Trips")
print(kable(all,format.args = list(big.mark = ","), digits = 0))
# Chunk 5: daily & peak trips
data_wddp <- read.csv("airsage/trip_leg_matrix_cusWDDP.csv")
data_wdh <- read.csv("airsage/trip_leg_matrix_cusWDH.csv")
data_wddp$tod <- "peak"
data_wdh$tod <- "24H"
data <- rbind(data_wddp, data_wdh)
print(head(data))
# Chunk 6: total trips
# Total trips
total_trips <- data %>% group_by(tod) %>% summarize(sum = sum(Count))
kable(total_trips,format.args = list(big.mark = ","), digits = 0)
# Chunk 7: trips by purpose
# Break down by purpose and period
samples <- data %>% group_by(tod, Purpose, Time_of_Day) %>% tally
trips <- data %>% group_by(tod, Purpose, Time_of_Day) %>% summarize(sum = sum(Count))
kable(left_join(samples,trips, by = c("Purpose" , "Time_of_Day", "tod")),
format.args = list(big.mark = ","), digits = 0)
# Chunk 8: daily trips
trips_by_type    <- data_wdh %>% group_by(Subscriber_Class) %>%
summarise(trips = sum(Count)) %>% arrange(Subscriber_Class)
trips_by_purpose <- data_wdh %>% group_by(Subscriber_Class, Purpose) %>%
summarise(trips = sum(Count)) %>% arrange(Subscriber_Class)
trips_by_OD      <- data_wdh %>% group_by(Origin_Zone, Destination_Zone) %>%
summarise(trips = sum(Count)) %>% spread(Destination_Zone, trips)
# Total trips
sum <- trips_by_type %>% summarise(total = sum(trips))
print(paste("Total trips = ", as.character(sum), sep =""))
# Compute percentage
trips_by_type    <- trips_by_type %>%  mutate(percent = 100 * trips/sum$total)
trips_by_purpose <- trips_by_purpose %>% mutate(percent = 100 * trips/sum(sum$total))
# Print summary
kable(trips_by_type,format.args = list(big.mark = ","), digits = 0)
kable(trips_by_purpose,format.args = list(big.mark = ","), digits = 0)
# District to district flows (limit this to Flagler districts)
trips_by_OD <- trips_by_OD[,2:41]
trips_by_OD[is.na(trips_by_OD)] <- 0
# Write output
write.csv(trips_by_OD, daily_od_matrix, row.names = FALSE)
# Chunk 9: peak trips
trips_by_type    <- data_wddp %>% group_by(Subscriber_Class) %>%
summarise(trips = sum(Count)) %>% arrange(Subscriber_Class)
trips_by_purpose <- data_wddp %>% group_by(Subscriber_Class, Purpose) %>%
summarise(trips = sum(Count)) %>% arrange(Subscriber_Class)
trips_by_period  <- data_wddp %>% group_by(Time_of_Day) %>%
summarise(trips = sum(Count)) %>% arrange(Time_of_Day)
trips_by_OD      <- data_wddp %>% group_by(Origin_Zone, Destination_Zone) %>%
summarise(trips = sum(Count)) %>% spread(Destination_Zone, trips)
# Total trips
sum <- trips_by_type %>% summarise(total = sum(trips))
print(paste("Total trips = ", as.character(sum), sep =""))
# Compute percentage
trips_by_type    <- trips_by_type %>%  mutate(percent = 100 * trips/sum$total)
trips_by_purpose <- trips_by_purpose %>% mutate(percent = 100 * trips/sum(sum$total))
trips_by_period  <- trips_by_period %>% mutate(percent = 100 * trips/sum(sum$total))
# Print summary
kable(trips_by_type,format.args = list(big.mark = ","), digits = 0)
kable(trips_by_purpose,format.args = list(big.mark = ","), digits = 0)
kable(trips_by_period,format.args = list(big.mark = ","), digits = 0)
write.csv(trips_by_OD, peak_od_matrix, row.names = FALSE)
# Chunk 10: airsage shapes
# Add airsage district file
shape <- readOGR(airsage_shapeFile, layer = "TAZs", verbose = FALSE)
# Read District equivqlency file
taz_dist <- read.csv(airsage_Districts)
# Append districts to 40 Zones
shape@data <- left_join(shape@data, taz_dist, by = "TAZ")
# Chunk 11: district locations
# Compute centroids
shape_polySet <- SpatialPolygons2PolySet(shape)
# Calculate the centroids
centroids <- calcCentroid(shape_polySet, rollup=1)
shape@data <- cbind(shape@data, centroids)   # Assume internal order matching
# Create study area spatial data
studyShape <- subset(shape, Districts %in% Study_districts)
# select colors based on Area Names
pal_fact <- colorFactor(topo.colors(6), shape$PlnArea)
map <- leaflet() %>%
# Base Map
addProviderTiles("Stamen.Toner",group = "Stamen") %>%
addTiles(group = "OSM") %>%
setView(lng = -80.1918, lat = 25.7617, zoom = 10) %>%
# add district shape files
addTiles %>%
addPolygons(
data = shape, group = "Dist Polyline", smoothFactor = 0.5,
stroke = TRUE,  weight = 3, color = "grey",opacity = 0.5,
fill = FALSE) %>%
# Color districts and create as a new layer
addPolygons(
data = shape, group = "Districts", smoothFactor = 0.5,
stroke = TRUE,  weight = 3, color = "grey",opacity = 0.5,
fill = TRUE, fillOpacity = 0.5,
fillColor = ~pal_fact(PlnArea)
) %>%
# Add Study area districts as a layer
addPolygons(
data = studyShape, group = "Flagler Corridor", smoothFactor = 0.5,
stroke = TRUE,  weight = 3, color = "black",opacity = 1.0,
fill = TRUE, fillOpacity = 0.75,
fillColor = "black"
) %>%
# Add district names
addCircleMarkers(data = shape, lng = shape$X, lat = shape$Y,
weight = 1, label =   ~as.character(shape$Districts),
radius = 1, labelOptions = labelOptions(noHide = T),
group = "Districts Labels") %>%
# Add control
addLayersControl(
baseGroups = c("OSM","Stamen"),
overlayGroups = c("Districts","Districts Labels","Flagler Corridor"),
options = layersControlOptions(collapsed = FALSE)
) %>%
hideGroup(c("Districts Labels"))
# Chunk 12: add flagler routes
# Read GTFS files
gtfsShapes <- read.csv(gtfsShapesFile)
gtfsTrips <- read.csv(gtfsTripsFile)
gtfsRoutes <- read.csv(gtfsRoutesFile)
# Get Flagler shape point from above three files
flaglerShape <- gtfsShapes %>%
left_join(gtfsTrips, by = "shape_id") %>%
left_join(gtfsRoutes, by = "route_id") %>%
filter(grepl(routeName, route_long_name, ignore.case = TRUE)) %>%
select (route_id, shape_id, route_long_name, route_color,
shape_pt_lat, shape_pt_lon, shape_pt_sequence,
shape_dist_traveled) %>%
distinct()
# Generate from and to data points from shape points
flaglerShape <- flaglerShape %>% group_by(shape_id) %>%
rename(from_lat = shape_pt_lat, from_lon = shape_pt_lon) %>%
mutate(to_lat = lead(from_lat, 1),
to_lon = lead(from_lon, 1)) %>%
ungroup() %>%
filter(!is.na(to_lat))
total_shapes <- unique(flaglerShape$shape_id)
factpal <- colorFactor(topo.colors(8), flaglerShape$shape_id)
# Map data
map <- map %>%
# Base Map
addProviderTiles("Stamen.Toner",group = "Stamen") %>%
addTiles(group = "OSM") %>%
setView(lng = -80.1918, lat = 25.7617, zoom = 10) %>%
addCircles(data = flaglerShape, lng = ~from_lon, lat = ~from_lat,
weight = 1, radius =100, color = ~factpal(shape_id),
popup = ~paste0("Route: ", route_long_name), group = "Flagler Routes"
) %>%
# Add control
addLayersControl(
baseGroups = c("OSM","Stamen"),
overlayGroups = c("Districts","Districts Labels","Flagler Corridor", "Flagler Routes"),
options = layersControlOptions(collapsed = FALSE)
) %>%
hideGroup(c("Districts Labels"))
map
# Chunk 13: study_area_daily
# 1. Create Daily flagler matrix (II, EI/IE, EE through Flagler districts)
study_wdh <- data_wdh %>% mutate(
study_Os = ifelse (Origin_Zone %in% Study_districts,
"StudyArea", "Outside"
),
study_Ds = ifelse (Destination_Zone %in% Study_districts,
"StudyArea", "Outside"
)
)
trips_by_OD      <- study_wdh %>% group_by(study_Os, study_Ds) %>%
summarise(trips = sum(Count)) %>% spread(study_Ds, trips) %>%
as.data.frame() %>% select(-study_Os) %>% add_marginals()
row.names(trips_by_OD) <- colnames(trips_by_OD)
pct_trips_by_OD <- 100 * trips_by_OD / trips_by_OD["total","total"]
kable(trips_by_OD,format.args = list(big.mark = ","), digits = 0)
kable(pct_trips_by_OD,format.args = list(big.mark = ","), digits = 2)
# 2. Create Daily flagler matrix to other districts
study_wdh <- data_wdh %>% mutate(
study_Os = ifelse (Origin_Zone %in% Study_districts,
min(Study_districts), Origin_Zone
),
study_Ds = ifelse (Destination_Zone %in% Study_districts,
min(Study_districts), Destination_Zone
)
)
trips_by_OD      <- study_wdh %>% group_by(study_Os, study_Ds) %>%
summarise(trips = sum(Count)) %>% spread(study_Ds, trips) %>%
as.data.frame() %>% select(-study_Os) %>% add_marginals()
# Write output
write.csv(trips_by_OD, daily_od_submatrix, row.names = FALSE)
# Compute to & from Study Area flows (& pct flows)
study_origins <- trips_by_OD %>% filter(row.names(trips_by_OD) == "20")
study_origins_pct <- 100 * study_origins / study_origins$total
study_destination <- trips_by_OD %>% select(20) %>% t() %>% as.data.frame()
study_destination_pct <- 100 * study_destination / study_destination$total
studyarea_flows <- bind_rows(study_origins,
study_origins_pct,
study_destination,
study_destination_pct
) %>%
t() %>% as.data.frame
colnames(studyarea_flows) <- c("Origins", "Origin_Pct", "Destination", "Dest_Pct")
kable(studyarea_flows,format.args = list(big.mark = ","), digits = 2)
# generate chord diagram
df <- remove_marginals(trips_by_OD)
m <- as.matrix(df)
dimnames(m) <- list(Origins = row.names(df), Destinations = row.names(df))
groupColors <-colorRampPalette(c("blue", "red", "green"))(20)
chorddiag(m, groupColors = groupColors, groupnamePadding = 20, showTicks = FALSE)
